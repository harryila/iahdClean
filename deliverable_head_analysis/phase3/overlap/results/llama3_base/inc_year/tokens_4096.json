{
  "method": "overlap_ablation",
  "description": "Ablation of QRHead \u2229 Wu24 overlap heads vs each method alone",
  "model_key": "base",
  "model_name": "meta-llama/Meta-Llama-3-8B",
  "question": "inc_year",
  "question_prompt": "What year was the company incorporated?",
  "total_tokens": 4096,
  "test_samples": 32,
  "n_overlap": 10,
  "overlap_jaccard": 0.1111,
  "timestamp": "2026-02-11T01:03:22.520004",
  "baseline": {
    "accuracy": 0.9375,
    "correct": 30,
    "total": 32
  },
  "conditions": {
    "overlap": {
      "num_heads": 10,
      "heads_str": [
        "L14H0",
        "L15H3",
        "L20H14",
        "L17H24",
        "L22H13",
        "L19H3",
        "L17H27",
        "L16H0",
        "L18H20",
        "L8H9"
      ],
      "accuracy": 0.96875,
      "accuracy_drop": -0.03125,
      "correct": 31,
      "total": 32
    },
    "wu24_top_n": {
      "num_heads": 10,
      "heads_str": [
        "L27H21",
        "L14H28",
        "L8H11",
        "L26H13",
        "L16H8",
        "L24H17",
        "L14H0",
        "L5H10",
        "L23H14",
        "L16H1"
      ],
      "accuracy": 1.0,
      "accuracy_drop": -0.0625,
      "correct": 32,
      "total": 32
    },
    "qrhead_top_n": {
      "num_heads": 10,
      "heads_str": [
        "L17H2",
        "L14H30",
        "L16H5",
        "L15H3",
        "L14H0",
        "L14H31",
        "L16H27",
        "L8H8",
        "L17H27",
        "L14H7"
      ],
      "accuracy": 0.96875,
      "accuracy_drop": -0.03125,
      "correct": 31,
      "total": 32
    }
  }
}